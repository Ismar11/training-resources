{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "Packages are pre-built python 'pieces' that we can install and import into our workspace for making our life easier. There's a vast variety of packages in the world. Here we'll be using few of the most common ones when it comes to data analysis and visualization.\n",
    "\n",
    "- **pandas:** A very popular tabular data manipulation library. It allows you to format and work with your data with table-like objects named Data Frames.\n",
    "- **numpy:** Numerical analysis library with a wide range of mathematical libraries and matrix operations. If you have used Matlab before this one will look familiar.\n",
    "- **widgets:** It will enable interactive controls in order to tweak the plots.\n",
    "- **matplotlib:** The classic plotting library.\n",
    "- **plotly:** Another cool plotting library with a more friendly and interactive skin. \n",
    "- **seaborn:** Built on top of matplotlib, tailored for easy descriptive statistical plots on your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-14T07:05:57.659977Z",
     "start_time": "2020-02-14T07:05:54.617826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_\"Statisticl Inference is the act of **generalizing** from a **sample** to a **population** with calculated **degree of cetainty**\"_ , Casella Berger (Statistical Inference).\n",
    "\n",
    "\n",
    "<img src='./images/Statistical_Inference.png' style=\"width:600px;'heigth:600px'\"/>\n",
    "\n",
    "\n",
    "**Generalization:**\n",
    "\n",
    "It refers to our ability to approximate population **parameters** with in sample statistics (aka moments). These \"approximates\" are named as **estimators** and statistics are its output known as **estimates**.  E.g., we can define a mean value of our sample data $X_{s}$ as $\\hat{\\mu} = f(X_{s}) = \\frac{1}{N}\\sum_{i=1}^{N} x_{i}$. In this case, $f(X_{s})$ is our estimator and $\\hat{\\mu}$ is the estimate.\n",
    "\n",
    "**Population:**\n",
    "\n",
    "In simple terms, it is the \"absolute\" data collection of targeted events that we'd like to learn about. E.g., the expected expenditure ($G^{e}$) of incoming tourists. However, one could argue that $G^{e}$ might not provide any useful information, given that $G^{e}$ may drastically vary across different geographic / demographic groups. The concept of **sub-population** comes to the rescue. E.g., instead of studying $G^{e}$ of the entire world population, we might split it into regions and get something like: $G^{e}_{North Europe},G^{e}_{North America}$, etc.\n",
    "\n",
    "Regardless whether we go with **sub-populations** or not, the core takeaway is that for a given case study / experiment, the targeted **population** contains all available data in existence (all people on the planet, all stars in the Universe, every particle that has gone through the space and time, etc.)\n",
    "\n",
    "**Sample:**\n",
    "\n",
    "Given the definition of a **population**, it is not usually feasible to access the entirety of it. I.e., given some natural constraints, we have to work with an arbitrary data collection known as a **sample**. On of its characteristics is that it is generated by a **sampling-procedure** applied on the results of a **data collection process**.  E.g., in the QA studies it is not feasible to have all clients to answer questioners, have 100% honest answers, and other frictions. Thus, in order to have the best **estimate** of clients satisfaction we'd have to deliberatly select the most representative and trustworthy **sample**. In other words, **sampling-procedure** and **data collection process** must be unbiased and flawless.\n",
    "\n",
    "**Uncertainty & Confidence: (TO FINISH)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2656)\n",
    "pop_height = np.random.normal(170, 15, 1000000)\n",
    "height_min = int(min(pop_height))\n",
    "height_max = int(max(pop_height))\n",
    "population = pd.DataFrame(pop_height, columns = ['Height'])\n",
    "del pop_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_plot(N, Height, SamplingMethod, seed):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    np.random.seed(seed)\n",
    "    sns.distplot(population['Height'], label='Population', hist=False)\n",
    "    if SamplingMethod == 'Random':\n",
    "        sns.distplot(population['Height'].sample(N),\n",
    "                     label='Sample',\n",
    "                     hist=False)\n",
    "    else:\n",
    "        sns.distplot(population.loc[population['Height'].\n",
    "                                    between(Height[0], Height[1]), 'Height'].sample(N),\n",
    "                     label='Sample',\n",
    "                     hist=False)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SamplingMethod = widgets.Dropdown(options=['Random', 'Selection Biased'],\n",
    "                                  value='Random',\n",
    "                                  descriptions='Sampling Method')\n",
    "Height = widgets.IntRangeSlider(value=[height_min, height_max],\n",
    "                                min=height_min,\n",
    "                                max=height_max,\n",
    "                                step=5,\n",
    "                                descriptions='Height Range')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e13eb7d127440d29430b2d328b3de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntText(value=1000, description='N'), IntRangeSlider(value=(98, 240), description='Heighâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(dist_plot,\n",
    "         N=widgets.IntText(1000),\n",
    "         Height=Height,\n",
    "         SamplingMethod=SamplingMethod,\n",
    "         seed=widgets.IntText());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interesting cases:(TO FINISH)**\n",
    "\n",
    "Participation bias https://en.wikipedia.org/wiki/Participation_bias\n",
    "\n",
    "Simpson's paradox https://en.wikipedia.org/wiki/Simpson%27s_paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "In simple terms, a probability distribution is a mathematical function $f(\\cdot)$ that attempts to study the behaviour of a random variable (RV) $X$ in terms of its possible outcomes. More formally, $f(X) \\doteq Pr(X = x)$ if $X$ is a discrete RV; $f(X) \\doteq Pr(a \\leq X \\leq b)$ if $X$ is a continuous RV. The former one can be reffered as **Probability Mass Function** (**pmf**), while the later is **Probability Density Function** (**pdf**). This distinction is of fundamental importance. \n",
    "\n",
    "In the simpliest example of a RV $X \\in [0,1]$, and Uniform Probability Distribution, if $X$ is discrete then $Pr(X = 0) = Pr(X = 1) = 1/|X| = 1/2 : X \\in \\mathbb{Z}^{[0,1]}$; if $X$ is a continuous RV then $Pr(X = x) = 1/|X| = 1/\\inf = 0$  $\\forall x \\in X:X \\in \\mathbb{R}^{[0,1]}$. However, if in the continuous case we used **pdf** instead of **pmf** we would get the desired answer: $Pr(0 \\leq X \\leq 0.5) = Pr(0.5 \\leq X \\leq 1) = 1/2$, which makes sense, given that 50% of all cases is contained within $[0,0.5]$ and $[0.5,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uniform Distribution:**\n",
    "\n",
    "This distribution assumes that all possible realizations of a given RV $X$ are equally likely and bounded to some arbitrary interval $[a,b]$. More formally:\n",
    "\n",
    "\n",
    "$$X \\sim U(a,b) : f(x,a,b) \\doteq \\begin{cases}\n",
    "  \\frac{1}{b - a} & \\mathrm{for}\\ a \\le x \\le b, \\\\[8pt]\n",
    "  0 & \\mathrm{for}\\ x<a\\ \\mathrm{or}\\ x>b\n",
    "  \\end{cases}$$\n",
    "\n",
    "<img src='./images/Uniform Distribution.png' style=\"width:600px;'heigth:600px'\"/>\n",
    "\n",
    "\n",
    "Use cases:\n",
    "1. RNG\n",
    "2. Generalization of other distributions with equally probable outcome scenarios (E.g. Bernoulli with fair dice / coins, etc.)\n",
    "3. Studying the scenarios of launching a new product (if no useful information is available for conditioning the outcomes)\n",
    "4. Others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian (Normal) Distribution:**\n",
    "\n",
    "Defines the behaviour of a continious RV $X$ in terms of its expected realization $E(X) = \\mu$ (a.k.a location) and the spread of this realization $Var(X) = \\sigma$ (a.k.a scale). More formally: \n",
    "\n",
    "\n",
    "$$X \\sim N(\\mu, \\sigma) : f(x,\\mu,\\sigma) \\doteq \\frac{1}{\\sigma \\sqrt{2 \\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$$\n",
    "\n",
    "\n",
    "<img src='./images/Normal Distribution.svg' style=\"width:600px;'heigth:600px'\"/>\n",
    "\n",
    "Use cases:\n",
    "1. CLT\n",
    "2. Statistical Inference\n",
    "3. Complex Distribution Aproximization (e.g via GMM)\n",
    "4. Errors / Noise Modeling (e.g for Image Noise Injection, error propagation, models generalization improvement, etc.)\n",
    "5. Generative modeling (VAE, GAN, etc.)\n",
    "6. Others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Poisson Distribution:**\n",
    "\n",
    "It is a discrete probability distribution function of the number of events to happen in a given time interval, provided the information about the average occurrence of those events.\n",
    "\n",
    "$$X \\sim P(k,\\lambda) : f(k,\\lambda) = \\frac{\\lambda^{k}e^{-\\lambda}}{k!}$$\n",
    "\n",
    "Where $k$ is the number of occurrences and $\\lambda$ is the expected number of occurrences.\n",
    "\n",
    "<img src='./images/Poisson Distribution.png' style=\"width:600px;'heigth:600px'\"/>\n",
    "\n",
    "There are conditions to be met in order to apply Poisson Distribution:\n",
    "1. There are no constraints on the amount of times a given event can occur during the chosen time interval\n",
    "2. Occurrence of events is independent between each other\n",
    "3. The rate of occurance must be stationary\n",
    "4. The probability of an event occurring is proportional to the length of the time period\n",
    "\n",
    "Use cases:\n",
    "1. Supply Chain Management\n",
    "2. Intermittent Demand Forecasting\n",
    "3. Capacity Planning (Contact centers, attention personnel in hospitals, etc.)\n",
    "4. Betting / Gambling\n",
    "5. Poisson Regression is for analysis of countable variables (e.g the number of sold tickets by the end of this month, this quarter, this year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bernoulli**\n",
    "\n",
    "It is a discrete probability distribution of a RV $X$ to have value $x$ with probability $p$ and $1-x$ with probability $1-p$. Where $x$ is a binary choice (True or False, To be or not to be, etc.). More formally:\n",
    "\n",
    "$$X \\sim B(p) : f(x,p) \\doteq x^{p}(1-x)^{1-p} = \\begin{cases} \n",
    "  x \\ \\text{, with probability p}, \\\\[8pt]\n",
    "  1-x \\  \\text{, with probability 1 - p}\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  \n",
    "<img src='Bernoulli Distribution.png' style=\"width:600px;'heigth:600px'\"/>\n",
    "\n",
    "\n",
    "Use cases:\n",
    "1. Whenever a binary choice is involved. Clinical trials, A/B testing, gambling, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** \n",
    "    \n",
    "1. I will drop the explaination of concepts such as unbiasedness and consitency of an estimaor. Since, I consider that these concepts are out of the scope of this workshop.\n",
    "\n",
    "2. As examples I will use the following distributions: Normal and Bernoulli.\n",
    "\n",
    "3. For simplicity sake, we will skip examples of 3rd & 4th moments.\n",
    "\n",
    "4. We assume univariate distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution's Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "Given a sample $X_{s} = \\{x_{1},...,x_{N}\\}$ drawn from a population $X$, $\\hat{x}$ is the **expected** realization of the population mean $\\overline{x}$, i.e $\\hat{x}$ is its estimate.\n",
    "\n",
    "More formally:\n",
    "\n",
    "$$\\hat{x} = E(X_s)$$\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "_Normal Distribution_ : $X_{s} \\sim N(\\hat{\\mu},\\hat{\\sigma})$\n",
    "\n",
    "$$E(X_{s}) = \\frac{1}{N}\\sum_{i=1}^{N} x_{i} = \\hat{\\mu}$$\n",
    "\n",
    "_Bernoulli Distribution_ : $X_{s} \\sim Bernoulli(\\hat{p})$\n",
    "\n",
    "$$E(X_{s}) = Pr(X_{s}=1)\\cdot1 + Pr(X_{s}=0)\\cdot0 = \\hat{p}\\cdot1 = \\hat{p}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution's  Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T10:05:52.829648Z",
     "start_time": "2020-02-13T10:05:52.823689Z"
    }
   },
   "source": [
    "**Definition:**\n",
    "\n",
    "Given a sample $X_{s} = \\{x_{1},...,x_{N}\\}$ drawn from a population $X$, $\\hat{\\sigma}^2$ is the **estimate** of the population variance $\\sigma^2$, i.e how **ucnertain** or **spread** a given distribution is.\n",
    "\n",
    "More formally:\n",
    "\n",
    "$$\\hat{\\sigma}^2 = Var(X_{s}) : Var(X_{s}) = E[(X_{s} - E(X_{s}))^2] = E(X_{s}^2) - E(X_{s})^2$$\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "_Normal Distribution_ : $X_{s} \\sim N(\\hat{\\mu},\\hat{\\sigma})$\n",
    "\n",
    "$$Var(X_{s})  = \\frac{1}{N-1}\\sum_{i=1}^{N} (x_{i} - \\hat{\\mu})^2 = \\hat{\\sigma}^2 \\text{, where} \\frac{1}{N-1} \\text{ is correction factor that guarantees unbiasedness}$$\n",
    "\n",
    "_Bernoulli Distribution_ : $X_{s} \\sim Bernoulli(\\hat{p})$\n",
    "\n",
    "$$Var(X_{s}) = E(X_{s}^2) - E(X_{s})^2 = Pr(X_{s}^2=1^2)\\cdot1^2 - \\hat{p}^2 = \\hat{p} - \\hat{p}^2 = \\hat{p}\\cdot(1-\\hat{p})$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution's  Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "Given a sample $X_{s} = \\{x_{1},...,x_{N}\\}$ drawn from a population $X$, $\\hat{\\mu}_{3}$ is the estimate of $\\mu_{3}$ that quantifies the asymmetry of a given probability distribution about its mean.\n",
    "\n",
    "There are various definitions of sample skewness. The most common one is _\"The Natural Method of Moments\"_ :\n",
    "\n",
    "$$\\hat{\\mu}_{3} = Skew(X_{s}) = \\frac{E[(X_{s} - E(X_{s}))^3]}{\\sqrt{E[(X_{s} - E(X_{s}))^2]^3}}$$\n",
    "\n",
    "**Utility**: It is usually used in the study of real-valued continous distributions with finite skewness, with the goal to measure their \"deviation\" from the normal distribution. This is of high importance, given that many statistical inferences adopted by business practitioners are only valid if the distribution normality is guaranteed. E.g. in presence of high skewness you can forget about implementing t-tests, your p-values will become asymetrical & misleading, classical ANOVA might fail, the intervals around the mean won't be trustworthy, and others.\n",
    "\n",
    "**NOTE:** $\\hat{\\mu}_{3}$ estimators tend to be highly biased in the case of mixture distributions. Best working with symmetrical real-valued continious distributions with finite skewness. The proposed sample method is implicitly biased, this implicit bias can be accounted by a correction factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution's  Kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definition:**\n",
    "\n",
    "Given a sample $X_{s} = \\{x_{1},...,x_{N}\\}$ drawn from a population $X$, $\\hat{\\mu}_{4}$ is the estimate of $\\mu_{4}$ that quantifies the propensity of a given probability distribution to produce extreme values.\n",
    "\n",
    "There are various definitions of sample kurtosis. The most common one is _\"The Natural Method of Moments\"_ :\n",
    "\n",
    "$$\\hat{\\mu}_{4} = Kurt(X_{s}) = \\frac{E[(X_{s} - E(X_{s}))^4]}{\\sqrt{E[(X_{s} - E(X_{s}))^2]^4}} = \\frac{E[(X_{s} - E(X_{s}))^4]}{E[(X_{s} - E(X_{s}))^2]^2}$$\n",
    "\n",
    "**Utility**: The obvious use case of $\\hat{\\mu}_{4}$ is to determine whether a given data distribution is affected by outliers. Other use case is related to the information theory. In particular, variables whose probability distributions have low kurtosis will lead to higher information entropy, i.e. lower predictive power. Vice versa for higher kurtosis. In multivariate scenarios, the information entropy can be used as a criterion for variable selection. There are other use cases.\n",
    "\n",
    "**NOTE:** $\\hat{\\mu}_{4}$ estimators tend to be highly biased in the case of mixture distributions (with some exceptions). The proposed sample method is implicitly biased, this implicit bias can be accounted by a correction factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary Statistics\n",
    "\n",
    "**Median:**\n",
    "\n",
    "The value which separates data distribution in two equal halves. More formally, if $|X|$ is even, then the index of the median is $\\frac{|X|+1}{2}$. If set $|X|$ is odd, then $Median(X) = \\frac{X(a_{l}) + X(a_{u})}{2} : a_{l} = \\frac{|X|}{2}, a_{u} = \\frac{|X|}{2}+1$\n",
    "\n",
    "E.g., $X = \\{1,2,3,4,5\\}$, $|X|$ is even, then, $Median(X) = X(\\frac{n+1}{2}) = 3$; $X = \\{1,2,2,4,5,6\\}$, $|X|$ is odd, then, $Median(X) = \\frac{X(3)+X(4)}{2} = \\frac{2+4}{2} = 3$\n",
    "\n",
    "The primary use cases of median are: studying probability distribution properties (normality, skewness, etc.), developing of outlier-robust metrics, outlier-robust learning models, and outliers detectors.\n",
    "\n",
    "**Mode:**\n",
    "\n",
    "The most frequent element of a given set $X$. More formally, if $X$ is a discrete probability distribution, then, $Mode(X) = \\operatorname*{arg\\,max}_x pmf(X = x)$, where $pmf$ is the probability mass function. If $X$ is a continuous probability distribution, then, $Mode(X) = \\{x_{i}^{*}\\}: \\forall x_{i}^{*} \\text{ it is guaranteed that } f(x_{i}^{*}) \\ge f(x_{i}^{*} \\pm \\epsilon)$, where $\\epsilon$ is an arbitrary small value and $f(\\cdot)$ is the liklihood function. In other words, the mode of a continuous probability distribution is a set of all maxima of its probability density function ($pdf$).\n",
    "\n",
    "E.g., $X = \\{1,2,2,4,5,6\\}$, $X$ is discrete, then, $Mode(X) = 2$; $X \\sim N(\\mu,\\sigma^2)$. If $X$ follows a normal-unimodal-symmetrical distribution, then $Mode(X) \\doteq \\frac{\\partial X}{\\partial x} = 0$, where $x^{*} = \\operatorname*{arg\\,max}_x X = \\mu$.\n",
    "\n",
    "The primary use cases of mode are: studying probability distribution properties (normality, skewness, \"modality\", etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Multivariate Statistics  (TO FINISH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Covariance & Correlation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation vs Causation**\n",
    "\n",
    "https://www.youtube.com/watch?v=VMUQSMFGBDo\n",
    "\n",
    "https://www.youtube.com/watch?v=8B271L3NtAw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Visual example for Correlation /= Causation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T14:29:42.153610Z",
     "start_time": "2020-02-13T14:29:42.147633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
